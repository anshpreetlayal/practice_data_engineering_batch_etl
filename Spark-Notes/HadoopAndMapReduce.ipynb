{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadoop and MapReduce\n",
    "\n",
    "Hadoop is an open-source framework for distributed storage and processing of large datasets across clusters of commodity hardware. It is designed to scale from a single server to thousands of machines, each offering local computation and storage. MapReduce is a programming model and processing engine used by Hadoop for processing and generating large data sets.\n",
    "\n",
    "### Components of Hadoop\n",
    "\n",
    "1. **Hadoop Distributed File System (HDFS)**: A distributed file system that provides high-throughput access to application data. It is designed to be fault-tolerant and suitable for use on large clusters of commodity hardware.\n",
    "\n",
    "2. **MapReduce**: A programming model for processing large datasets in parallel across a distributed cluster. It consists of two main phases: the Map phase, where data is processed in parallel, and the Reduce phase, where the results from the Map phase are combined to produce the final output.\n",
    "\n",
    "3. **YARN (Yet Another Resource Negotiator)**: A resource management layer in Hadoop that manages resources in the cluster and schedules jobs.\n",
    "\n",
    "### MapReduce Programming Model\n",
    "\n",
    "- **Map Phase**: In this phase, input data is divided into splits, and a map function is applied to each split in parallel. The output of the map function is a set of key-value pairs.\n",
    "\n",
    "- **Shuffle and Sort Phase**: The output of the map phase is shuffled and sorted by key to group together values associated with the same key.\n",
    "\n",
    "- **Reduce Phase**: In this phase, the reduce function is applied to each group of values with the same key, producing the final output.\n",
    "\n",
    "### Example:\n",
    "Consider a simple word count example using MapReduce:\n",
    "\n",
    "1. **Map Phase**: For each word in the input text, emit a key-value pair `(word, 1)`.\n",
    "\n",
    "2. **Shuffle and Sort Phase**: Group together all `(word, 1)` pairs with the same word.\n",
    "\n",
    "3. **Reduce Phase**: For each group of `(word, [1, 1, 1, ...])` pairs, sum up the counts to get the total count for that word.\n",
    "\n",
    "### Hadoop Ecosystem\n",
    "\n",
    "Hadoop has a rich ecosystem of tools and libraries that extend its functionality:\n",
    "\n",
    "- **Apache Hive**: A data warehouse infrastructure built on top of Hadoop that provides a SQL-like query language (HiveQL) for querying and managing large datasets.\n",
    "\n",
    "- **Apache Pig**: A high-level platform for creating MapReduce programs used for analyzing large datasets.\n",
    "\n",
    "- **Apache Spark**: An open-source, distributed computing system that provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. It can run on top of Hadoop YARN.\n",
    "\n",
    "- **Apache HBase**: A distributed, scalable, big data store that provides random, real-time read/write access to large datasets.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
