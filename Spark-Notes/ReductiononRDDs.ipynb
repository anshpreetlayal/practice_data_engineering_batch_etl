{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction Operations on RDDs: `fold` and `aggregate`\n",
    "\n",
    "In Apache Spark, `fold` and `aggregate` are two reduction operations that allow you to combine the elements of an RDD into a single result. While both operations are used for aggregation, they differ in their usage and capabilities.\n",
    "\n",
    "### `fold` Operation\n",
    "\n",
    "- **Definition**: The `fold` operation in Spark is used to aggregate the elements of an RDD using a binary function and an initial \"zero value.\" The zero value is used as an initial accumulator for each partition, and then the binary function is used to combine the accumulator with each element of the partition.\n",
    "\n",
    "- **Syntax**:\n",
    "  ```scala\n",
    "  def fold(zeroValue: T)(op: (T, T) => T): T\n",
    "  ```\n",
    "\n",
    "- **Example**:\n",
    "  ```scala\n",
    "  val rdd = sc.parallelize(Seq(1, 2, 3, 4, 5))\n",
    "  val sum = rdd.fold(0)((acc, ele) => acc + ele)\n",
    "  ```\n",
    "\n",
    "- **Behavior**:\n",
    "  - The `fold` operation starts with the `zeroValue` for each partition.\n",
    "  - It then applies the `op` function to combine the `zeroValue` with each element of the partition to produce a single result for that partition.\n",
    "  - Finally, it combines the results from all partitions using the `op` function to produce the final result.\n",
    "\n",
    "### `aggregate` Operation\n",
    "\n",
    "- **Definition**: The `aggregate` operation in Spark is similar to `fold` but allows you to return a different type of result. It takes three arguments: an initial \"zero value,\" a function to combine elements within each partition, and a function to combine results from different partitions.\n",
    "\n",
    "- **Syntax**:\n",
    "  ```scala\n",
    "  def aggregate[U](zeroValue: U)(seqOp: (U, T) => U, combOp: (U, U) => U): U\n",
    "  ```\n",
    "\n",
    "- **Example**:\n",
    "  ```scala\n",
    "  val rdd = sc.parallelize(Seq(1, 2, 3, 4, 5))\n",
    "  val result = rdd.aggregate((0, 0))(\n",
    "    (acc, ele) => (acc._1 + ele, acc._2 + 1),\n",
    "    (acc1, acc2) => (acc1._1 + acc2._1, acc1._2 + acc2._2)\n",
    "  )\n",
    "  val avg = result._1.toDouble / result._2\n",
    "  ```\n",
    "\n",
    "- **Behavior**:\n",
    "  - The `aggregate` operation starts with the `zeroValue` for each partition.\n",
    "  - It then applies the `seqOp` function to combine each element of the partition with the `zeroValue` to produce a partial result for that partition.\n",
    "  - Finally, it combines the partial results from all partitions using the `combOp` function to produce the final result.\n",
    "\n",
    "### Comparison\n",
    "\n",
    "- **Use Case**:\n",
    "  - Use `fold` when you need to aggregate elements of an RDD into a single result using a simple binary function.\n",
    "  - Use `aggregate` when you need more control over the aggregation process, such as when you need to return a different type of result or when you need to perform different aggregation operations within and across partitions.\n",
    "\n",
    "- **Performance**:\n",
    "  - `fold` can be more efficient than `aggregate` for simple aggregation tasks because it avoids the overhead of creating and merging partial results.\n",
    "  - `aggregate` is more flexible but may incur higher overhead due to the need to create and merge partial results.\n",
    "\n",
    "\n",
    "\n",
    "### **Distributed Key-Value Pairs in Spark RDDs**\n",
    "\n",
    "In Apache Spark, RDDs (Resilient Distributed Datasets) can represent key-value pairs, where each element in the RDD is a tuple `(key, value)`. This allows you to perform operations that are specific to key-value pairs, such as grouping by key, joining, and aggregating.\n",
    "\n",
    "### Creating a Pair RDD\n",
    "\n",
    "You can create a Pair RDD from an existing RDD by using the `map` transformation to convert each element into a key-value pair. For example:\n",
    "```scala\n",
    "val rdd = sc.parallelize(Seq(\"key1\" -> 1, \"key2\" -> 2, \"key1\" -> 3))\n",
    "val pairRDD = rdd.map { case (key, value) => (key, value) }\n",
    "```\n",
    "\n",
    "### Transformation Operations on Pair RDDs\n",
    "\n",
    "1. **Grouping by Key**: Use the `groupByKey` transformation to group values with the same key together.\n",
    "   ```scala\n",
    "   val groupedRDD = pairRDD.groupByKey()\n",
    "   ```\n",
    "\n",
    "2. **Reduce by Key**: Use the `reduceByKey` transformation to apply a reduction function to values with the same key.\n",
    "   ```scala\n",
    "   val sumByKeyRDD = pairRDD.reduceByKey(_ + _)\n",
    "   ```\n",
    "\n",
    "3. **Sorting by Key**: Use the `sortByKey` transformation to sort the RDD by key.\n",
    "   ```scala\n",
    "   val sortedRDD = pairRDD.sortByKey()\n",
    "   ```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
