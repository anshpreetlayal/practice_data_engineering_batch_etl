# Practice Data Engineering Batch ETL

## Description
An extensive portfolio showcasing my experience in batch ETL processes, featuring projects utilizing Apache Hadoop, Spark, and various data warehousing technologies like Amazon Redshift and Google BigQuery. This repository highlights my ability to design and implement robust ETL and ELT pipelines, integrating cutting-edge big data frameworks and cloud-based solutions.

## Repository Contents
1. **Apache Spark for Batch ETL**
   - Spark Core Concepts
     - Understanding Spark's distributed computing model
     - RDD (Resilient Distributed Dataset) creation and transformations
   - Data Processing with Spark SQL and DataFrames
     - Utilizing DataFrames for structured data manipulation
     - Querying data with Spark SQL
   - Performance Optimization in Spark
     - Tuning Spark configurations for efficiency
     - Memory management and serialization optimizations

<!-- -->

## Projects


## How to Use
Provide instructions on how to use or run the projects in this repository.

## License
This project is licensed under the Apache License, Version 2.0. See the [LICENSE](LICENSE) file for details.