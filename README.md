# practice_data_engineering_batch_etl

Description: "An extensive portfolio of my experience in batch ETL processes, featuring projects utilizing Apache Hadoop, Spark, and various data warehousing technologies like Amazon Redshift and Google BigQuery. This repository showcases my ability to design and implement robust ETL and ELT pipelines, integrating cutting-edge big data frameworks and cloud-based solutions."

1.1.1 Apache Spark for Batch ETL

Spark Core Concepts:

Understanding Spark's distributed computing model.

RDD (Resilient Distributed Dataset) creation and transformations.

Data Processing with Spark SQL and DataFrames:

Utilizing DataFrames for structured data manipulation.

Querying data with Spark SQL.

Performance Optimization in Spark:

Tuning Spark configurations for efficiency.

Memory management and serialization optimizations.